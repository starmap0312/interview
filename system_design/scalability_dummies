# Part I: Clones
  1) user get the same results of his request, independent of what server he lands on
  2) every server contains exactly the same codebase
  3) server does not store any user related data, ex. sessions, on local disk or memory
  4) sessions are stored in a centralized data store accessible to all servers
     ex. an external database (ex. MySQL)
         an external persistent cache (ex. Redis): has better performance than database

# AMI: Amazon Machine Image
  a (virtual) hard drive snapshot
  1) a special type of virtual appliance that is used to create a virtual machine within
     the Amazon Elastic Compute Cloud (EC2)
  2) serves as the basic unit of deployment for services delivered using EC2
  3) create an image file, i.e. AMI, from one of the servers
     use the AMI as a super-clone that all new instances are based upon
     whenever you start a new instance/clone, just do an initial deployment

# large-scale deployment
  1) code change are sent to all servers
  2) deployment tool: Capistrano (written in Ruby)
     used to deploy web applications to multiple servers
     used to run scripts on multiple servers
     ex. deploy current changes to the web application or roll back to the previous deployment state

# Part II: Scalable Database Solutions

# Soluiton 1: MySQL
  master-slave replication: read from slaves, write to master (master need RAM)
  1) sharding
     a database shard is a horizontal partition of data in a database
     each shard is held on a separate database server instance to spread load
     a) some data remains present in all shards
     b) some data only appears in a single shard
  2) denormalization: do not use Joins in database query
     ex.
       a) a normalized schema
         SELECT product_name, order_date
         FROM orders INNER JOIN products USING(product_id)
         WHERE product_name LIKE 'A%' ORDER BY order_date DESC
       b) a denormalized schema: let the orders table include the product_name column as well
         SELECT product_name, order_date
         FROM orders
         WHERE product_name LIKE 'A%' ORDER BY order_date DESC 
  3) SQL tuning

# Soluiton 2: NoSQL
  use NoSQL database: MongoDB/CouchDB, easier to scale, denormalize right from the beginning
  let the application code do the dataset-joins

# Part III: Cache
  1) a simple key-value store: reside between application and data storage
  2) whenever application reads data, it should try to retrieve the data from cache first
     if not in the cache, get the data from the main data source
  3) in-memory caches: holds dataset in RAM
     ex. Redis/Memcached
         Redis can do several thousands of read operations per second
         writes, especially increments, are very fast
  4) never do file-based caching: makes cloning and auto-scaling of servers a pain

# Pattern 1: Cached Database Queries
  1) whenever do a query to database, store the result dataset in cache
  2) the next time you run the query, first check if it is already in the cache
  3) issue: expiration
     when one piece of data changes, ex. a table cell, you need to delete all cached queries
     that include the table cell

# Pattern 2: Cached Objects (better)
  1) view data as an object (i.e. caching class objects/instances in code)
  2) when class assembles a dataset from database, cache the complete instance of the class
     ex. class: Product with property: data
         data: an array containing prices, texts, and customer reviews, etc.
               assembled by several database requests (hard to cache)
         directly store the data array or the complete instance of the class, in the cache
     pros:
        you can easily get rid of the object when something changes
        the overall operation of your code is faster and more logical
        asynchronous processing becomes possible (let multiple servers assemble the object)
  3) common examples of cached objects
     a) user sessions (never use the database)
     b) fully rendered blog articles
     c) activity streams
     d) user <-> friend relationships 

# Part IV: Asynchronism
  service becomes responsive, handle millions of visitors/requests

# Paradigm 1: pre-computing 
  doing the time-consuming work in advance, serving the finished work with a low request time
  1) often, turn dynamic content into static content, i.e. pre-rendered HTML pages
     web pages are pre-rendered and locally stored as static HTML files on every change
     ex. a hourly cronjob that does the computing tasks

# Paradigm 2: handle tasks asynchronously, have a queue of jobs that a worker can process 
  1) used for special requests that cannot be preprocessed or for computing intensive tasks 
  2) server pushishes a job onto a queue and immediately signals back to the user
  3) a bunch of workers constantly check the job queue
     if there is a new job, the worker does the job and sends a signal when the job is done
  4) the frontend constantly checks for job-done signals and informs the user about it
  5) async processing implementations: RabbitMQ, ActiveMQ, or a simple Redis list

# Apache ActiveMQ
  1) open source messaging and Integration Patterns server
  2) written in Java with a full Java Message Service (JMS) client

# Redis list
  1) a Redis data type
  2) lists of strings, sorted by insertion order
  3) pushing new elements on the head (on the left) or on the tail (on the right) of the list

  example:
    LPUSH mylist a   => now the list is "a"
    LPUSH mylist b   => now the list is "b","a"
    RPUSH mylist c   => now the list is "b","a","c" (RPUSH was used this time)

# Message queue
  1) used for inter-process communication (IPC)
     used for inter-thread communication within the same process
  2) use a queue for messaging: the passing of control or of content
  3) a sibling of the publisher/subscriber pattern
     one part of a larger message-oriented middleware system

# Apache Kafka vs. RabbitMQ
  1) Kafka is a log, your writes are appended to the tail, but you can read from where you want, whereas
     RabbitMQ is queue FIFO (reading from the HEAD and processing one by one)
  2) Kafka is truly distributed: data is sharded, replicated, durability guarantees can be tuned, availability can be tuned, whereas
     RabbitMQ has limited support for the above

# Apache Kafka vs. Apache Storm
  1) Kafka: Distributed messaging system
     Storm: Real Time Message Processing
  2) Kafka is a distributed and robust queue, whereas
     Storm is not a queue
  3) Kafka can handle high volume real-time data, serving as a buffer/queue: it enables you to pass messages from one endpoint to another
     Storm is a system that has distributed real time processing abilities : it executes all kind of manipulations on real time data in parallel
  
  common use case/data flow:
    real-time-system --> Kafka (Queue) --> Storm (Parallel Processing) --> NoSql (Persistent Indexed Storage) --> Bussiness Intelligence (optional)
  a) your real time app handling high volume data, sends it to Kafka queue
  b) Storm pulls the data from Kafka and applies some required manipulation
  c) the data is then stored to some NoSql DB for additional BI calculations (or simply queried by other systems)

# Apache Storm vs. Akka
  Both systems scale very well and can handle large amounts of data
  1) Storm is a distributed, real-time computation system
       on a Storm cluster, you execute topologies, which process streams of tuples (data)
       each topology is a graph consisting of spouts (which produce tuples) and bolts (which transform tuples)
       Storm takes care of cluster communication, fail-over and distributing topologies across cluster nodes
     Akka is a toolkit for building distributed, concurrent, fault-tolerant applications
       in an Akka application, the basic construct is an actor
       Actors process messages asynchronously, and each actor instance is guaranteed to be run using at most one thread at a time, making concurrency much easier
       Actors can also be deployed remotely
       thereâ€™s a clustering module, which will handle automatic fail-over and distribution of actors across cluster nodes
  2) Storm's basic unit of data is a "tuple"
       a tuple can have any number of elements, and each tuple element can be any object, as long as there is a serializer for it
     Akka's basic unit is a "message"
       a message can be any object and should be serializable as well (for sending it to remote actors)
  3) Storm's basic unit of computation are "bolts" and "spouts"
       a bolt can be any piece of code, which does arbitrary processing on the incoming tuples
       a bolt can store some mutable data, ex. to accumulate results
       a bolt runs in a single thread, so you do not have to worry about concurrent access to the bolt's data
     Akka's basic unit of computation are "actors"
  4) Actors & Bolts: Similarities
     i)  Both bolts and actors are expected to do some processing basing on the data received
         bolts can receive arbitrary tuples, and actors can receive arbitrary messages
     ii) Both bolts and actors have internal state
         their internal state is private and protected from concurrent thread access
  5) Actors & Bolts: Differences
     i)   how actors and bolts communicate:
          Storm is only one-way and cannot send back messages
            note: Bolts "ack" messages, which is a form of communication, to the ackers
            note: you can send a tuple to a named channel (stream), i.e. broadcast the tuple (message) to all listeners
          Actor can send a message to any other actor, as long as it has the ActorRef (and if not, an actor can be looked up by-name)
            ex. actor can send back a reply to the sender of the message that is being handled
     ii)  routing (random/hashing vs. multiple options):
          in Storm, multiple copies of a bolt/sprout code can be run in parallel (depending on the parallelism setting)
            tuples can be routed to bolt instances (in random, or by consistent hashing on a field)
          in Akka, the above result can be achieved by using a set of (potentially remote) actors with a load-balancer actor in front of them
            the above can be achieved by using router option of round robin, or consistent hashing on the message
     iii) weights (dedicated thread vs. shared threads):
          in Storm, the expected number of bolts is significantly smaller (a design decision)
            each bolt instance tends to have a dedicated thread
          in Akka, it is normal to have lots of actors (up to millions)
            actors typically share threads
     iv)  layout of the communication:
          in Storm, the topology is static and defined upfront
          in Akka, the communication patterns can change over time and can be dynamic
          actors can send messages to any other actors, or can even send addresses (ActorRefs)
      v) overall:
         Storm implements a specific range of usages
         Akka is more of a general-purpose toolkit
         i.e. it would be possible to build a Storm-like system on top of Akka, but not the other way round
  6) Other features:
     i) Storm has a crucial feature of "guaranteed message delivery"
        it tracks the whole tree of tuples that originate from any tuple produced by a sprout
        if not all tuples aren acknowledged, the tuple will be "replayed"
    ii) Storm's cluster management is more advanced
        it uses Zookeeper for automatic "fail-over", automatic "balancing" of workers across the cluster
        Akka is also developing more advanced clustering module 

